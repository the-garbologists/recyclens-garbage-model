{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recyclens Image Data Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QShPnpt6mDxC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.image import *\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualise(original, augmented):\n",
        "  fig = plt.figure()\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title('Original Image')\n",
        "  plt.imshow(original)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title('Augmented Image')\n",
        "  plt.imshow(augmented)"
      ],
      "metadata": {
        "id": "qROJQWULmMon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(source_path, destination_path):\n",
        "  ''' performing image augmentation on existing images and shifting augmented image files to their corresponding categories'''\n",
        "  for image_path in source_path:\n",
        "      seed = (1,0)\n",
        "      image = cv2.imread(image_path)\n",
        "      aug_image1 = stateless_random_brightness(image, max_delta=0.4, seed=seed)\n",
        "      aug_image1 = flip_left_right(aug_image1)\n",
        "      visualise(image, aug_image1)\n",
        "\n",
        "      aug_image2 = stateless_random_contrast(image, lower=0.25, upper=0.75, seed=seed)\n",
        "      aug_image2 = flip_up_down(aug_image2)\n",
        "      visualise(image, aug_image2)\n",
        "\n",
        "      aug_image3 = stateless_random_jpeg_quality(image, min_jpeg_quality=25, max_jpeg_quality=75, seed=seed)\n",
        "      aug_image3 = stateless_random_crop(aug_image3, size=[108, 180, 3], seed=seed)\n",
        "      visualise(image, aug_image3)\n",
        "\n",
        "      aug_image_list = [aug_image1, aug_image2, aug_image3]\n",
        "      aug_image_list_new = []\n",
        "      for aug_image in aug_image_list:\n",
        "        aug_image = tf.keras.preprocessing.image.array_to_img(aug_image)\n",
        "        aug_image = aug_image.resize((224,224), Image.ANTIALIAS)\n",
        "        aug_image_list_new.append(aug_image)\n",
        "\n",
        "      head, tail = os.path.split(image_path)\n",
        "      file, ext = os.path.splitext(tail)\n",
        "      for aug_image_new in aug_image_list_new:\n",
        "        extension = file + '_aug_image_' + str(aug_image_list_new.index(aug_image_new) + 1) + ext\n",
        "        aug_image_new.save(destination_path + '/' + extension)\n"
      ],
      "metadata": {
        "id": "-Puxb4iXmUpx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}